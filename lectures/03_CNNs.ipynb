{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From FNNs to CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/fnn_jf.png\" width=550>\n",
    "\n",
    "(*Slide by J.Frellsen*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So we just talked about word embeddings\n",
    "\n",
    "i.e., word embeddings are a **dense continuous** representations of a word\n",
    "\n",
    "Typically when talking about word embeddings we think of a **matrix E** which encodes |V| * d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How can we represent a text in continuous dense space?\n",
    "\n",
    "$$ w_i,..,w_n $$ ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing text in continuous dense space: The CBOW model\n",
    "\n",
    "A simple classification model that uses embeddings as representation is the CBOW model: it uses the sum (or average) of the embeddings of the words in the sentence. The CBOW representation is feeded into a fully connected network. It often works surprisingly well.\n",
    "\n",
    "$$ \\mbox{CBOW}(w_i,..,w_n) = \\sum_i^n E[w_i] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So far so good, but wait a minute\n",
    "\n",
    "What is a fundamental downside of the CBOW model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Convolutional neural networks (CNNs or convnets) are a  specialized kind of neural network **for processing data that has a known, grid-like topology** [[1](http://www.deeplearningbook.org/contents/convnets.html)].\n",
    "* A method that evolved from **computer vision (CV)** (LeCun & Bengio, 1995)\n",
    "* E.g., image classification, caption generation, photo tagging, self-driving cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A convolutional neural network is designed\n",
    "to identify indicative local predictors in a large structure, and combine them to produce a\n",
    "fixed size vector representation of the structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are convnets / CNNs?\n",
    "\n",
    "* CNNs use convolutions over the input to compute the output\n",
    "* Each layer applies *different filters* (often several hundreds or thousands) and combines their results\n",
    "* combining the results of the convolutions is often done by **pooling**\n",
    "\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example of a 2d convolution\n",
    "\n",
    "* input (e.g., image)\n",
    "* convolution: kernel/filter (of size 3x3)\n",
    "<img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\">\n",
    "\n",
    "Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Image data**: 2-dimensional (matrix/grid) \n",
    "* **Text data**: 1-d (sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* CV intuition - invariance in data:\n",
    "  * we want to find an object regardless of its position in the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/cnn_eq_jf.png\" width=550 alt=\"Slide by J.Frellsen\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What are convolutions?\n",
    "\n",
    "* a *convolution* is an operation (of two functions) where one is the **input**, the other is a **kernel** that acts like a **filter** on the input producing an output\n",
    "* we are sliding the *kernel* over the input; it computes for example a windowed averaged representation of the input vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* in simple terms: a grid that goes over the input\n",
    "* **filter**: a function that helps \"identifying indicative local predictors\" (Goldberg, 2015)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a filter? (kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/cnn_filters_jf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is a convolution? Mathematical view\n",
    "\n",
    "Convolution is an important operation in signal and image processing;\n",
    "it operates on either images (2D) or texts (1D). \n",
    "\n",
    "Think of one as the\n",
    "**input signal**. The other, the **kernel acts as a filter** on the input producing\n",
    "an **output**.\" [[2](http://www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf), [3](https://www.inf.ed.ac.uk/teaching/courses/nlu/lectures/nlu_l15_convolution-2x2.pdf)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Definition\n",
    "\n",
    "Imagine a 1d (image) input vector\n",
    "\n",
    "* $f$ is our input vector of length $n$\n",
    "* $g$ is our kernel (filter) of lenght $m$\n",
    "\n",
    "The convolution $f*g$ of $f$ and $g$ is defined as:\n",
    "$$(f * g)(i) = \\sum_{j=1}^m g(j)\\cdot f(i-j+m/2)$$\n",
    "\n",
    "* Think at this as sliding the kernel over the input image\n",
    "* For each position of the kernel, we multiply the overlapping values of the kernel and image together and add up the results, to produce the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "Let's look at a simple example. Suppose our input 1d image $f$ is:\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "10 | 50 | 60 | 10 | 20| 40 | 30 \n",
    "---\n",
    "\n",
    "and our kernel $g$ is: \n",
    "\n",
    "---\n",
    "|1/3 |1/3 |1/3| \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's assume we want to compute the value of $h(3)$ (j is at position 3). To compute this, we slide the kernel so that it is centered around $f(3)$:\n",
    "\n",
    "| 10 | 50 | 60 | 10 | 20| 40 | 30 |\n",
    "|--|--|--|--|--|--|--|\n",
    "|  | 1/3 | 1/3 | 1/3 | | | |  |\n",
    "\n",
    "To compute this, we will assume that the value of the kernel is 0 everywhere outside the boundary, and then we can compute the weighted sum (dot product):\n",
    "\n",
    "| 10 | 50 | 60 | 10 | 20| 40 | 30 |\n",
    "|--|--|--|--|--|--|--|\n",
    "| 0 | 1/3 | 1/3 | 1/3 |0 | 0 | 0 | \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, \n",
    "\n",
    "$50 * \\frac{1}{3} + 60 * \\frac{1}{3} + 10 * \\frac{1}{3} = 40$\n",
    "\n",
    "Thus $h(3) = 40$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 60 10]\n",
      "[0.33333333 0.33333333 0.33333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Example in code\n",
    "import numpy as np\n",
    "\n",
    "f = np.array([10,50,60,10,20,40,30])\n",
    "g = np.array([1/3,1/3,1/3])\n",
    "\n",
    "window = f[1:4]\n",
    "print(window)\n",
    "print(g)\n",
    "np.dot(window,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is this kernel doing?\n",
    "\n",
    "Computing the moving average of the image, i.e., replacing each entry with the average of the entry and its left and right neighbor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutions for text\n",
    "\n",
    "* CNNs were introduced in NLP by Collobert et al. (2011) and later by Kim (2014) and Kalchbrenner et al. (2014)\n",
    "* the intention is to let the network focus on the most important \"features\" in the sentence, regardless of their location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main idea behind a convolution and pooling architecture for language tasks is to apply\n",
    "a non-linear (learned) function over each instantiation of a $k$-word sliding window over\n",
    "the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"soft\" n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pics/cnn-goldberg.png\">\n",
    "Illustration from Goldberg (2015) chapter 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "    \n",
    "* **convolution**: a $k$-word sliding window is input for a function (**filter**) that transforms the window of k words into a $d$ dimensional vector (where each dimension is called a **channel**)\n",
    "* **pooling**: then, a pooling operation combines vectors from different windows into a $d$-dim vector by taking the **max** (max-pooling) or **average** value observed in each of the channels (max pooling/average pooling)\n",
    "\n",
    " The resulting vector is a representation for the entire sentence in which each dimension represents the most salient features for some prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In more detail, including mathematical formulation:\n",
    "\n",
    "<img src=\"pics/cnn-illustration.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The gradients that are propagated\n",
    "back from the network’s loss during the training process are used to tune the parameters\n",
    "of the filter function to highlight the aspects of the data that are important for the task\n",
    "the network is trained for. Intuitively, when the sliding window is run over a sequence, the\n",
    "filter function learns to identify informative k-grams. (Goldberg, 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also do different convolutions on different parts of the sentence/document (see section 9.2, Goldberg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CNN hyperparameters\n",
    "\n",
    "* how would you apply the filter to the first element of a matrix\n",
    "that doesn’t have any neighboring elements to the top and left?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* zero-padding: all elements that fall outside of the matrix are zero.\n",
    "wide convolution vs narrow convolution\n",
    "* **wide convolution vs narrow convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CNN hyperparameters\n",
    "\n",
    "* **stride** size: how much (how many 'pixels') you shift your filter at each step\n",
    "* If stride size is 1, consecutive applications of the filter overlap\n",
    "\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pooling\n",
    "\n",
    "* Max pooling: “Did you see this feature anywhere in the\n",
    "range?” (most common)\n",
    "* Average pooling: “How prevalent is this feature over the\n",
    "entire range”\n",
    "* k-Max pooling: “Did you see this feature up to k times?” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/poolings.jpg\" width=550>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stride 2\n",
    "\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png\">\n",
    "Src: http://cs231n.github.io/convolutional-networks/#pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kim (2014)\n",
    "\n",
    "* apply several convolutional layers in parallel: multi-channel method\n",
    "* each filter comes with its own set of parameters\n",
    "<img src=\"pics/kim2014.png\">\n",
    "\n",
    "We first embeds words into the embedding space. The next layer performs convolutions over the embedded word vectors using multiple filter sizes. For example, sliding over 3, 4 or 5 words at a time. Next, we max-pool the result of the convolutional layer into a long feature vector, add dropout regularization, and classify the result using a softmax layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example:\n",
    "\n",
    "An CNN with different branches\n",
    "\n",
    "* CNN-rand: all words are randomly initialized and then modified during training\n",
    "* CNN-static: pre-trained vectors with all the words— including the unknown ones that are randomly initialized—kept static and only the other parameters of the model are learned\n",
    "* CNN-non-static: same as CNN-static but word vectors are fine-tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/cnn-branches.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to implement a CNN in Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 48, 250)           96250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 1,441,510\n",
      "Trainable params: 1,441,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=128, input_dim=10000, input_length=50))\n",
    "\n",
    "num_filters = 250\n",
    "conv_length = 3  # filter size (number of words we want our convolutional layer to cover)\n",
    "# we will have a total number of filters: num_filters * filter_size \n",
    "hidden_dims = 250\n",
    "\n",
    "# we add a Convolution1D, which will learn num_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters=num_filters,  # Number of convolution kernels to use (dimensionality of the output).\n",
    "                 kernel_size=conv_length, #  The extension (spatial or temporal) of each filter.\n",
    "                 padding='valid',  #valid: don't go off edge; same: use padding before applying filter\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "# max pooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back to our sentiment example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# load data - convert to indices, pad to max_length - y's no n-hot needed as this is a binary task\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "positive_sentences = [l.strip() for l in open(\"data/rt-polarity.pos\").readlines()]\n",
    "negative_sentences = [l.strip() for l in open(\"data/rt-polarity.neg\").readlines()]\n",
    "\n",
    "positive_labels = [1 for sentence in positive_sentences]\n",
    "negative_labels = [0 for sentence in negative_sentences]\n",
    "\n",
    "sentences = np.concatenate([positive_sentences,negative_sentences], axis=0)\n",
    "labels = np.concatenate([positive_labels,negative_labels],axis=0)\n",
    "\n",
    "## make sure we have a label for every data instance\n",
    "assert(len(sentences)==len(labels))\n",
    "data={}\n",
    "np.random.seed(113) #seed\n",
    "data['target']= np.random.permutation(labels)\n",
    "np.random.seed(113) # use same seed!\n",
    "data['data'] = np.random.permutation(sentences)\n",
    "\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(data['data'], data['target'], test_size=0.2)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_rest, y_rest, test_size=0.2)\n",
    "del X_rest, y_rest\n",
    "\n",
    "## map them to ids for embedding layer\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "PAD = w2i[\"<pad>\"] # index 0 is padding\n",
    "UNK = w2i[\"<unk>\"] # index 1 is for UNK\n",
    "\n",
    "# convert words to indices, taking care of UNKs\n",
    "X_train_num = [[w2i[word] for word in sentence.split(\" \")] for sentence in X_train]\n",
    "w2i = defaultdict(lambda: UNK, w2i) # freeze - cute trick!\n",
    "X_dev_num = [[w2i[word] for word in sentence.split(\" \")] for sentence in X_dev]\n",
    "X_test_num = [[w2i[word] for word in sentence.split(\" \")] for sentence in X_test]\n",
    "\n",
    "max_sentence_length=max([len(s.split(\" \")) for s in X_train] \n",
    "                        + [len(s.split(\" \")) for s in X_dev] \n",
    "                        + [len(s.split(\" \")) for s in X_test] )\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# pad X\n",
    "X_train_pad = sequence.pad_sequences(X_train_num, maxlen=max_sentence_length, value=PAD)\n",
    "X_dev_pad = sequence.pad_sequences(X_dev_num, maxlen=max_sentence_length, value=PAD)\n",
    "X_test_pad = sequence.pad_sequences(X_test_num, maxlen=max_sentence_length,value=PAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train instances: 6823 #dev: 1706 #test: 2133\n"
     ]
    }
   ],
   "source": [
    "print(\"#train instances: {} #dev: {} #test: {}\".format(len(X_train),len(X_dev),len(X_test)))\n",
    "\n",
    "vocabulary_size = len(w2i)\n",
    "embeds_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(113) #set seed before any keras import\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embeds_size, input_length=max_sentence_length))\n",
    "\n",
    "# A simple (single filter) CNN with filter_size 3\n",
    "\n",
    "num_filters = 250\n",
    "conv_length = 4\n",
    "hidden_dims = 250\n",
    "\n",
    "# we add a Convolution1D, which will learn num_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters=num_filters,  # Number of convolution kernels to use (dimensionality of the output).\n",
    "                 kernel_size=conv_length, #  The extension (spatial or temporal) of each filter.\n",
    "                 padding='valid',  #valid: don't go off edge; same: use padding before applying filter\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "# max pooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "6823/6823 [==============================] - 5s 804us/step - loss: 0.6663 - acc: 0.6011\n",
      "Epoch 2/4\n",
      "6823/6823 [==============================] - 5s 800us/step - loss: 0.4216 - acc: 0.8164\n",
      "Epoch 3/4\n",
      "6823/6823 [==============================] - 5s 781us/step - loss: 0.1616 - acc: 0.9436\n",
      "Epoch 4/4\n",
      "6823/6823 [==============================] - 5s 730us/step - loss: 0.0471 - acc: 0.9881\n",
      "1706/1706 [==============================] - 0s 124us/step\n",
      "Accuracy:  76.26025790625971\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, epochs=4, batch_size=50)\n",
    "loss, accuracy = model.evaluate(X_dev_pad, y_dev)\n",
    "\n",
    "print(\"Accuracy: \", accuracy *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* [Goldberg's primer chapter 9](arxiv.org/abs/1510.00726)\n",
    "* [WildML: CNNs for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/#more-348)\n",
    "* [Cornell course notes](http://www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf)\n",
    "* [David's blogpost](http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
